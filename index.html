<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dabin Kim | Music & Audio AI Researcher</title>
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:ital,wght@0,400;0,700;1,400&family=Lora:ital,wght@1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="assets/css/index.css">
</head>
<body>
    <header class="main-header">
        <div class="container">
            <a href="#about" class="logo">Dabin Kim</a>
            <nav class="main-nav">
                <ul>
                    <li><a href="#about">Home</a></li>
                    <li><a href="#publications">Publications</a></li>
                    <li><a href="projects/index.html" class="nav-disabled" aria-disabled="true">Projects</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container">

        <section id="about">
            <div class="hero">
                <img src="timbre-transfer/figs/profile_rect.jpeg" alt="Profile photo of Dabin Kim" class="profile-image">
                <div class="hero-text">
                    <h1>Dabin Kim 김다빈</h1>
                    <p class="hero-email"><a href="mailto:dabinchi9598@kaist.ac.kr">dabinchi9598@kaist.ac.kr</a></p>
                    <p class="hero-bio">AI researcher exploring new paradigms to understand and generate music.</p>
                </div>
            </div>
            <div style="background-color: #f8f9fa; padding: 20px 25px; border-radius: 8px; margin-top: 30px;">
                <div class="education-list">
                    <h3>News</h3>
                    <ul>
                        <li>
                            <p>Ph.D. in Music and Audio Computing (MAC) Lab</p>
                            <p class="period">Mar 2026 - Present</p>
                        </li>
                        <li>
                            <p>Sony CSL Assistant Researcher</p>
                            <p class="period">Jul 2025 - Oct 2025</p>
                        </li>
                        <li>
                            <p>M.S. in Music and Audio Computing (MAC) Lab</p>
                            <p class="period">Aug 2023 - Expected Aug 2025</p>
                        </li>
                        <li>
                            <p>B.S. in Art & Technology, Sogang University</p>
                            <p class="period">Feb 2017 - Feb 2023</p>
                            <p class="details">&mdash; Double Major in Big Data Science</p>
                        </li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="publications">
            <h2 class="section-title">Publications</h2>
            <ul class="item-list">
                <li>
                    <h3><a href="#">Text-Guided Instrument Timbre Transfer with Target-Adaptive Structural Control</a></h3>
                    <p class="authors"><strong>Dabin Kim</strong>, Juhan Nam</p>
                    <p class="venue"><em>Master's Thesis, planned for ICASSP 2026 Submission</em></p>
                    <!--
                    <p class="summary">
                        As the first author, this work addresses a key limitation in timbre transfer where instrument-specific expressive features (e.g., vibrato, loudness shimmer) embedded in fine-grained pitch and loudness signals hinder accurate timbre reproduction. My proposed method improves this by adaptively adjusting the influence of source-target aware pitch and loudness information. In comparison with ControlNet and SmartControl-based methods, my model achieves the highest target timbre fidelity (measured by CLAP-MS, CLAP-LAION) when conditioned simultaneously on a 50-cent resolution fundamental frequency (f0) contour and a 32-bin RMS loudness contour.
                    </p>
                    -->
                    <div class="links">
                        <a href="#" target="_blank">[Paper]</a>
                        <a href="timbre-transfer/" target="_blank">[Demo]</a>
                        <a href="#" target="_blank">[Code]</a>
                    </div>
                </li>
                <li>
                    <h3><a href="https://arxiv.org/abs/2408.11915" target="_blank">Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound</a></h3>
                    <p class="authors">Junwon Lee, Jaekwon Im, <strong>Dabin Kim</strong>, Juhan Nam</p>
                    <p class="venue"><em>TASLP</em>, 2025.</p>
                    <!--
                    <p class="summary">
                        In this project, my contributions included working with Optical Flow for video-to-audio tasks. I was also responsible for designing and participating in the qualitative evaluation of the generated sounds.
                    </p>
                    -->
                    <div class="links">
                        <a href="https://arxiv.org/abs/2408.11915" target="_blank">[Paper]</a>
                        <a href="https://jnwnlee.github.io/video-foley-demo/" target="_blank">[Demo]</a>
                        <a href="https://github.com/jnwnlee/video-foley" target="_blank">[Code]</a>
                    </div>
                </li>
                <li>
                    <h3><a href="https://ismir2024program.ismir.net/lbd_480.html" target="_blank">Pitch-ControlNet: Continuous Pitch Control for Monophonic Instrument Sound Generation</a></h3>
                    <p class="authors"><strong>Dabin Kim</strong>*, Junwon Lee*, Minseo Kim*, Juhan Nam</p>
                    <p class="venue"><em>Late Breaking Demo, ISMIR 2024</em></p>
                    <!--
                    <p class="summary">
                        As a co-author, I contributed to the development of this model, focusing on MIDI-level structural control. My specific role involved designing the module that processes MIDI pitch contours to guide the Text-to-Audio diffusion model with ControlNet architecture.
                    </p>
                    -->
                    <div class="links">
                        <a href="https://ismir2024program.ismir.net/lbd_480.html" target="_blank">[Paper]</a>
                        <a href="#" target="_blank">[Demo]</a>
                        <a href="#" target="_blank">[Code]</a>
                    </div>
                </li>
            </ul>
        </section>
        
        <!-- Projects section removed - accessible via navigation only -->
    </main>

    <footer id="contact" class="main-footer">
        <div class="contact-info">
            <a href="mailto:dabinchi98@kaist.ac.kr">Email</a>
            <a href="https://github.com/dabinkim" target="_blank">GitHub</a>
            <a href="#" target="_blank">Google Scholar</a>
            <a href="#" target="_blank">LinkedIn</a>
            <a href="#">[Download CV]</a>
        </div>
        <p class="copyright">&copy; 2025 Dabin Kim. All rights reserved.</p>
    </footer>
</body>
</html>
